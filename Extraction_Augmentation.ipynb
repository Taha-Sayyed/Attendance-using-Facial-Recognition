{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "id": "9XwKqs0ASGjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tco2zF1Cm3Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9ls-p39H6kP"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "from mtcnn import MTCNN\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the MTCNN face detector.\n",
        "detector = MTCNN()"
      ],
      "metadata": {
        "id": "K0oeKeQmSPdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Extraction Code ---\n",
        "video_path = \"/content/drive/MyDrive/Face_Recognition/Video Dataset/niraj_patil.mp4\"\n",
        "vid = cv2.VideoCapture(video_path)\n",
        "if not vid.isOpened():\n",
        "    print(\"Error: Video file cannot be opened. Please check the file path and file format.\")\n",
        "else:\n",
        "    print(\"Video file opened successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGD4ztmPIB-z",
        "outputId": "e1526e4b-1bc7-45a4-cc30-15c4c20d53f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video file opened successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the video frame rate and use a default if FPS is not available.\n",
        "fps = vid.get(cv2.CAP_PROP_FPS)\n",
        "if fps == 0:\n",
        "    print(\"FPS not detected, using default FPS = 30\")\n",
        "    fps = 30\n"
      ],
      "metadata": {
        "id": "jmiaHOgDJRNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate sampling interval to extract 5 frames per second.\n",
        "sample_rate = int(round(fps / 5))\n",
        "print(f\"Video FPS: {fps}, extracting every {sample_rate} frame(s) to get ~5 frames per second.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1eRGY3t9JUYd",
        "outputId": "a3be1e71-bf62-447e-c365-fd49b8869365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video FPS: 14.366519762640108, extracting every 3 frame(s) to get ~5 frames per second.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Output directory for original and augmented images.\n",
        "dir_path = \"/content/drive/My Drive/Face_Recognition/Dataset/Neeraj Nimbadas Patil\"\n",
        "if not os.path.exists(dir_path):\n",
        "    os.makedirs(dir_path)\n",
        "    print(f\"Creating the directory: {dir_path}\")\n",
        "else:\n",
        "    print(f\"{dir_path} already exists\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qvs4coE8Jt9E",
        "outputId": "4f4e535b-ba14-438f-fffc-bfc19fb84c81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/Face_Recognition/Dataset/Neeraj Nimbadas Patil already exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frame_counter = 0\n",
        "extracted_frames = 0"
      ],
      "metadata": {
        "id": "PvR9toFzJ5S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmentation parameters.\n",
        "resize_dim = (160, 160)\n",
        "h_shift = 20\n",
        "v_shift = 20\n",
        "brightness_alpha = 1.2\n",
        "brightness_beta = 30\n",
        "darkness_alpha = 0.7\n",
        "darkness_beta = -30\n",
        "blur_ksize = (7, 7)\n",
        "padding = 20  # padding in pixels"
      ],
      "metadata": {
        "id": "LVthe_aHJ8ZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    success, frame = vid.read()\n",
        "    if not success:\n",
        "        break\n",
        "\n",
        "    # Process only every sample_rate-th frame.\n",
        "    if frame_counter % sample_rate == 0:\n",
        "        # --- Padding the frame ---\n",
        "        padded_frame = cv2.copyMakeBorder(frame, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
        "\n",
        "        # --- Face Extraction using MTCNN ---\n",
        "        detections = detector.detect_faces(padded_frame)\n",
        "        if len(detections) == 0:\n",
        "            print(f\"No face detected in frame {frame_counter}. Skipping this frame.\")\n",
        "        else:\n",
        "            # Using the first detected face.\n",
        "            detection = detections[0]\n",
        "            x, y, w, h = detection['box']\n",
        "            # Ensure coordinates are positive.\n",
        "            x = max(0, x)\n",
        "            y = max(0, y)\n",
        "            face = padded_frame[y:y+h, x:x+w]\n",
        "\n",
        "            # Resize the cropped face image.\n",
        "            resized_face = cv2.resize(face, resize_dim)\n",
        "\n",
        "            # --- Save the Original Resized Face ---\n",
        "            original_filename = f\"{dir_path}/frame_{extracted_frames}_original.jpg\"\n",
        "            cv2_imshow(resized_face)  # Display the resized face image in Colab.\n",
        "            cv2.imwrite(original_filename, resized_face)\n",
        "\n",
        "            # --- Augmentation Steps ---\n",
        "            # 1. Horizontal Shift with Black Padding.\n",
        "            h_shifted = np.roll(resized_face, h_shift, axis=1)\n",
        "            if h_shift > 0:\n",
        "                h_shifted[:, :h_shift] = 0\n",
        "            else:\n",
        "                h_shifted[:, h_shift:] = 0\n",
        "\n",
        "            # 2. Vertical Shift with Black Padding.\n",
        "            v_shifted = np.roll(resized_face, v_shift, axis=0)\n",
        "            if v_shift > 0:\n",
        "                v_shifted[:v_shift, :] = 0\n",
        "            else:\n",
        "                v_shifted[v_shift:, :] = 0\n",
        "\n",
        "            # 3. Brightness Adjustment.\n",
        "            bright = cv2.convertScaleAbs(resized_face, alpha=brightness_alpha, beta=brightness_beta)\n",
        "\n",
        "            # 4. Darkness Adjustment.\n",
        "            dark = cv2.convertScaleAbs(resized_face, alpha=darkness_alpha, beta=darkness_beta)\n",
        "\n",
        "            # 5. Blurring.\n",
        "            blur = cv2.GaussianBlur(resized_face, blur_ksize, 0)\n",
        "\n",
        "            # 6. Flipping (Horizontal).\n",
        "            flip = cv2.flip(resized_face, 1)\n",
        "\n",
        "            # Save augmented images with descriptive filenames.\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_hshift.jpg\", h_shifted)\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_vshift.jpg\", v_shifted)\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_bright.jpg\", bright)\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_dark.jpg\", dark)\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_blur.jpg\", blur)\n",
        "            cv2.imwrite(f\"{dir_path}/frame_{extracted_frames}_flip.jpg\", flip)\n",
        "\n",
        "            extracted_frames += 1\n",
        "\n",
        "    frame_counter += 1\n",
        "\n",
        "vid.release()\n",
        "print(f\"Total extracted frames (and augmented sets): {extracted_frames}\")\n"
      ],
      "metadata": {
        "id": "qf1F67MpPj8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List all files in the directory and count them.\n",
        "all_files = os.listdir(dir_path)\n",
        "# Optionally, filter to count only JPEG images (if your frames are saved as .jpg).\n",
        "frame_files = [f for f in all_files if f.lower().endswith('.jpg')]\n",
        "print(\"Total frames (including augmented images):\", len(frame_files))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOTVEIuLNFwV",
        "outputId": "6c30f8ce-e480-459f-f895-a16ec4535830"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total frames (including augmented images): 161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IOhkroeN2Oq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}